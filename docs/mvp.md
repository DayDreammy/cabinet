# Cabinet MVP 最终定稿：The Golden Pipeline（黄金流水线）

## 1. MVP 目标
唯一目标：验证“全文语境阅读”是否显著提升**信任感**与**准确度**。

交付形态：
- 输出 5-8 条“原句证据 + 溯源链接 + 评分”。
- 所有证据必须来自原文内容（精确子串），可定位高亮。
- 前端通过“伪装成 Agent”的流程动效营造信任感。

## 2. 数据结构与约束（来自 `ps_2026-01-07.json`）
- 数据规模：3355 条。
- 字段结构：`id / title / question / content / url / publishedAt / updatedAt / proofread`。
- 数据来源：`zhihu.com`、`afdian.com` 为主。
- 内容长度差异大（存在空内容与超长内容），必须支持全文输入到 LLM。
- **铁律**：
  - 不改写、不总结，只能摘录原句。
  - 摘录必须是 `content` 的精确子串（用于高亮定位）。
  - `proofread` 仅做注释层展示，不作为摘录来源。

## 3. 逻辑架构（线性三步走，无分支）
### Step 1: 暴力检索（Brute-Force Search）
- 动作：对 JSON 做加权关键词匹配。
- 输入：用户 Query。
- 输出：Top 20 篇候选文章（Raw Candidates）。
- 目的：保证召回率，宁可错杀，不可放过。

加权建议（可调）：
- `title` 权重 2.0
- `question` 权重 1.5
- `content` 权重 1.0

分词策略：
- MVP 可用简单切分（空格/标点）作为起步。
- 若引入分词库，也只作用于 Step 1（不影响后续结构）。

### Step 2: 并发审阅（Parallel Review）
- 动作：将 20 篇候选并发送入 LLM 审阅。
- LLM：GLM-4.5-Flash（本地 OpenAI 兼容接口）。
- Prompt（固定模板）：
  - “你是审核员。这篇文章有没有回答这个问题？如果有，摘录原话；如果没有，返回空。”
- 输出：5-8 个包含金句的 JSON 对象。
- 目的：用 LLM 的理解能力替代关键词匹配，提高准确率。

### Step 3: 格式化组装（Assembly）
- 动作：按“相关度/精彩程度”排序，组装最终报告。
- 输出：给前端的最终 JSON。

## 4. “伪装成 Agent”的 UI（Wizard of Oz）
前端不展示真实后台结构，而是用动画脚本模拟 Agent 思考：
- T+0s：
  - `> 正在思考搜索策略...`
  - `> 执行检索：关键词 "护城河" + "定价权"`
- T+1s（Step 2 Start）：
  - `> 命中 20 篇文档，启动并发阅读引擎...`
- T+2s ~ T+10s（并发返回时流式推送）：
  - `《2021投资笔记》... ❌ 略过`（灰字淡出）
  - `《关于价值的思考》... ✅ 锁定核心观点`（绿字高亮，卡片弹出）
- T+12s：
  - `> 整理完成。为您精选 6 条证据。`
  - 切入 Split View 导读。

核心是“Manus Effect”：用户看到的是“有人在快速阅读”，实际是并发请求陆续回包。

## 5. 极简后端结构（Python + FastAPI）
不需要 LangChain，不需要图数据库，仅线性脚本即可。

建议文件结构：
- `main.py`：API 与 SSE 流式推送
- `search.py`：暴力检索（加权匹配）
- `review.py`：LLM 审阅（并发调用）

SSE 事件类型：
- `log`：阶段日志
- `log_skip`：跳过提示
- `card_found`：命中卡片
- `done`：流程结束

## 6. LLM 接口（本地 OpenAI 兼容）
使用 `http://127.0.0.1:8000/v1/chat/completions`。

请求示例：
```json
{
  "model": "glm-4.5-flash",
  "agentic": false,
  "temperature": 0.2,
  "max_tokens": 512,
  "messages": [
    {
      "role": "system",
      "content": "你是审核员，只能引用原文句子，禁止改写。"
    },
    {
      "role": "user",
      "content": "问题: <用户Query>\n\n文章标题: <title>\n文章内容: <content>\n\n任务: 如果文章回答了问题，返回原文摘录和相关度评分(0-10)；否则返回空。"
    }
  ]
}
```

响应处理要点：
- 如果返回为空或评分低于阈值（如 < 7），视为未命中。
- 命中时必须在 `content` 中定位摘录起止位置（`content.find(quote)`）。

## 7. 输出 JSON（给前端）
```json
{
  "query": "用户问题",
  "generated_at": "2026-01-07T12:00:00Z",
  "results": [
    {
      "id": "...",
      "title": "...",
      "url": "...",
      "quote": "原文摘录",
      "quote_start": 123,
      "quote_end": 156,
      "score": 8.7
    }
  ]
}
```

## 8. 验收标准（MVP）
- 单次查询 10-20 秒内完成（并发审阅可控）。
- 输出 5-8 条原句证据，且都能在原文中定位高亮。
- UI 能完整展示“搜索 -> 并发阅读 -> 整理完成”的流程动效。
- 用户主观反馈：相较于“摘要式回答”，更信任、更愿意自行阅读原文。

## 9. 暂不做（Out of Scope）
- 复杂 Agent 框架、工具链编排
- 语义膨胀/多路召回/密度重排序
- 多用户协作与权限系统
- 外部抓取与联网搜索
- 个性化推荐与画像建模
